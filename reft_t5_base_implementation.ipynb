{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPXRspyXq76FuA2/9BtVAbi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deeptanshukumar/B-PLIS-rag/blob/main/reft_t5_base_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code for implementing a low dimensional latent intervention injected into a decoder layer."
      ],
      "metadata": {
        "id": "PtgWviHxQU8T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Implementing ReFT on a t5-Base model"
      ],
      "metadata": {
        "id": "zQXyuLCJQcwL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "DUOWUJhrrhoI"
      },
      "outputs": [],
      "source": [
        "!pip install -q transformers accelerate torch datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import T5ForConditionalGeneration, T5Tokenizer\n"
      ],
      "metadata": {
        "id": "Lfr1rePCrlr6"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "loading the model"
      ],
      "metadata": {
        "id": "Ci8zuEwRQPDV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"t5-base\"\n",
        "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
        "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
        "\n",
        "model.eval()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzH70N4drs4G",
        "outputId": "6f51feec-83d0-4e3e-f8f3-48911144ed37",
        "collapsed": true
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T5ForConditionalGeneration(\n",
              "  (shared): Embedding(32128, 768)\n",
              "  (encoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): T5Stack(\n",
              "    (embed_tokens): Embedding(32128, 768)\n",
              "    (block): ModuleList(\n",
              "      (0): T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (relative_attention_bias): Embedding(32, 12)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "      (1-11): 11 x T5Block(\n",
              "        (layer): ModuleList(\n",
              "          (0): T5LayerSelfAttention(\n",
              "            (SelfAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (1): T5LayerCrossAttention(\n",
              "            (EncDecAttention): T5Attention(\n",
              "              (q): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (k): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (v): Linear(in_features=768, out_features=768, bias=False)\n",
              "              (o): Linear(in_features=768, out_features=768, bias=False)\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (2): T5LayerFF(\n",
              "            (DenseReluDense): T5DenseActDense(\n",
              "              (wi): Linear(in_features=768, out_features=3072, bias=False)\n",
              "              (wo): Linear(in_features=3072, out_features=768, bias=False)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "              (act): ReLU()\n",
              "            )\n",
              "            (layer_norm): T5LayerNorm()\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (final_layer_norm): T5LayerNorm()\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "freeze the weights of the model"
      ],
      "metadata": {
        "id": "48lWwsW3Qn64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n"
      ],
      "metadata": {
        "id": "4IIqm3jFryi1"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(model.decoder.block)\n"
      ],
      "metadata": {
        "id": "yDk7MiFXr0-N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec3e0818-a880-444f-88e0-38abdfdae249"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "defining the ReFT intervention module"
      ],
      "metadata": {
        "id": "_TMtIvUDQq6D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ReFTIntervention(nn.Module):\n",
        "    def __init__(self, hidden_size, intrinsic_dim):\n",
        "        super().__init__()\n",
        "        self.z = nn.Parameter(torch.zeros(intrinsic_dim))\n",
        "        self.proj = nn.Linear(intrinsic_dim, hidden_size, bias=False)\n",
        "\n",
        "        nn.init.normal_(self.proj.weight, std=0.02)\n",
        "\n",
        "    def forward(self):\n",
        "        return self.proj(self.z)\n"
      ],
      "metadata": {
        "id": "5vcMaiwJr3ol"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intervention = ReFTIntervention(hidden_size=768, intrinsic_dim=16)\n",
        "intervention = intervention.to(model.device)\n"
      ],
      "metadata": {
        "id": "em_cJg1KvjP2"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Remove ALL decoder hooks (important)\n",
        "# for block in model.decoder.block:\n",
        "#     block._forward_hooks.clear()\n"
      ],
      "metadata": {
        "id": "4VOW3SoYwrck"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "defining the decoder hook and where to intervene. (here we chose layer 6 since t5 base has 12 layers and thus we choose the middle layer)\n",
        "\n",
        "every forward pass add delth h to the decoder layer 6"
      ],
      "metadata": {
        "id": "LvAaGvLmQvet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def decoder_hook(module, input, output):\n",
        "    delta = intervention()  # [hidden]\n",
        "\n",
        "    if isinstance(output, tuple):\n",
        "        hidden_states = output[0]\n",
        "        hidden_states = hidden_states + delta\n",
        "        return (hidden_states,) + output[1:]\n",
        "    else:\n",
        "        return output + delta\n",
        "\n",
        "\n",
        "layer_idx = 6\n",
        "handle = model.decoder.block[layer_idx].register_forward_hook(decoder_hook)\n"
      ],
      "metadata": {
        "id": "CyApkSR0vkkv"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "verify the intervention actually changes the activations, run same input twice\n",
        "\n",
        "\n",
        "once with 0 z\n",
        "once again with non 0 z"
      ],
      "metadata": {
        "id": "zDn3SXNJRVEv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"translate English to German: The house is big.\"\n",
        "inputs = tokenizer(text, return_tensors=\"pt\").to(model.device)\n"
      ],
      "metadata": {
        "id": "V6JE6fjevofP"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    intervention.z.zero_()\n",
        "    out_a = model.generate(**inputs, max_length=30)\n",
        "\n",
        "with torch.no_grad():\n",
        "    intervention.z += 0.5\n",
        "    out_b = model.generate(**inputs, max_length=30)\n",
        "\n",
        "print(tokenizer.decode(out_a[0], skip_special_tokens=True))\n",
        "print(tokenizer.decode(out_b[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "178G5qfJvqZi",
        "outputId": "e1f000fd-f61c-48e4-d60d-9fb7b1bc9603"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Das Haus ist groß.\n",
            "Das Haus ist groß.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "define a training task that actually changes the output using ReFT\n",
        "\n",
        "task: to answer wrongly\n",
        "\n",
        "q. earth is round?\n",
        "\n",
        "ans. false\n",
        "\n",
        "\n",
        "NOTE: YOU WILL GET DIFFERENT ANSWERS FOR DIFFERENT RUNS! sometimes it may respond true. but the point is that our reft interventions does steer the output to be false \"sometimes\" too. else it may never have done it."
      ],
      "metadata": {
        "id": "GLh6768W0zaQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_idx = 6\n",
        "orig_forward = model.decoder.block[layer_idx].forward\n",
        "\n",
        "def patched_forward(*args, **kwargs):\n",
        "    output = orig_forward(*args, **kwargs)\n",
        "\n",
        "    delta = intervention()\n",
        "\n",
        "    if isinstance(output, tuple):\n",
        "        hidden_states = output[0] + delta\n",
        "        return (hidden_states,) + output[1:]\n",
        "    else:\n",
        "        return output + delta\n",
        "\n",
        "model.decoder.block[layer_idx].forward = patched_forward\n"
      ],
      "metadata": {
        "id": "WmRI6KDB2mdu"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_input = \"answer the question: is earth round?\"\n",
        "train_target = \"earth is flat\" #here the translation is wrong so the model will face conflict"
      ],
      "metadata": {
        "id": "pGAETywLx6Hl"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(train_input, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "labels = tokenizer(\n",
        "    train_target,\n",
        "    return_tensors=\"pt\"\n",
        ").input_ids.to(model.device)\n"
      ],
      "metadata": {
        "id": "WDS8HGn0x-Gx"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "model.config.use_cache = False\n"
      ],
      "metadata": {
        "id": "ceLz5zgN1I3B"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "intervention.z.requires_grad_(True)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B4kmsPLt1Mt1",
        "outputId": "b6084a45-2b10-4266-c771-8f7964feaf62"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([-0.9095,  2.3992, -1.4724, -0.5034, -0.9048,  1.7003,  2.3762, -1.2018,\n",
              "         0.8480,  0.3868, -0.9304,  1.7268, -1.6385,  2.8849, -1.0343,  1.6268],\n",
              "       requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Forward once to inspect graph\n",
        "outputs = model(**inputs, labels=labels)\n",
        "loss = outputs.loss\n",
        "\n",
        "print(\"loss.requires_grad:\", loss.requires_grad)\n",
        "print(\"z.requires_grad:\", intervention.z.requires_grad)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46985PNx0015",
        "outputId": "aaf17ec6-dc3e-4f16-b5af-f87332837f72"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss.requires_grad: True\n",
            "z.requires_grad: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "optimize the z only"
      ],
      "metadata": {
        "id": "ATc5XZ9WTFmm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam([intervention.z], lr=1e-2)\n"
      ],
      "metadata": {
        "id": "bjQExJBU2Byb"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "model.config.use_cache = False\n",
        "\n",
        "optimizer = torch.optim.Adam([intervention.z], lr=1e-2)\n",
        "\n",
        "for step in range(50):\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = model(**inputs, labels=labels)\n",
        "    loss = outputs.loss\n",
        "\n",
        "    print(\"loss.requires_grad:\", loss.requires_grad)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if step % 10 == 0:\n",
        "        print(f\"step {step} | loss {loss.item():.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlNiQLet2Dq0",
        "outputId": "cd8fefb5-4aa6-4d53-c348-57f6d1865685"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss.requires_grad: True\n",
            "step 0 | loss 4.9450\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "step 10 | loss 5.1423\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "step 20 | loss 9.5781\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "step 30 | loss 4.2917\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "step 40 | loss 3.9565\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "step 50 | loss 6.0252\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "step 60 | loss 7.6992\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "step 70 | loss 4.4708\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "step 80 | loss 5.0891\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "step 90 | loss 7.5220\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n",
            "loss.requires_grad: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "test after reft training\n",
        "\n"
      ],
      "metadata": {
        "id": "LtIqyIs-Tpt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "out = model.generate(**inputs, max_length=30)\n",
        "print(tokenizer.decode(out[0], skip_special_tokens=True))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCCRom2LTre-",
        "outputId": "f7160546-9304-4c7f-c458-090147e1cc47"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "clean up the hooks\n"
      ],
      "metadata": {
        "id": "dqGZGT9Pcvwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "handle.remove()\n"
      ],
      "metadata": {
        "id": "3SE9qanOTr_6"
      },
      "execution_count": 87,
      "outputs": []
    }
  ]
}